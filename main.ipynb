{"metadata":{"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import DBSCAN\n\nfrom pyriemann.clustering import Kmeans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('tb2_data_clean.csv', sep=';')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.iloc[:,1:3]\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Sum_of_squared_distances = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(data.values)\n    Sum_of_squared_distances.append(km.inertia_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_means = KMeans(n_clusters=3)\nk_means.fit(data.values)\nclusters = k_means.fit_predict(data.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data.values[:, 1], data.values[:, 0], c=clusters, s=50, cmap='viridis')\n\ncenters = k_means.cluster_centers_\nplt.scatter(centers[:, 1], centers[:, 0], c='red', s=200, alpha=0.5);\nplt.gca().set_box_aspect(0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def k_mean_distance(data, cx, cy, i_centroid, cluster_labels):\n    distances = [np.sqrt((x-cx)**2+(y-cy)**2) for (x, y) in data[cluster_labels == i_centroid]]\n    return distances\n\ndistances = []\nfor i, (cx, cy) in enumerate(centers):\n    print(i, cx, cy)\n    mean_distance = k_mean_distance(data.values, cx, cy, i, clusters)\n    distances.append(mean_distance)\n    print(min(distances[i]))\n    print(max(distances[i]))\n    print('-----------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jarak = pd.DataFrame(distances[0])\n\n\n# scaling data\nmms = MinMaxScaler()\nmms.fit(jarak)\nprint(mms.data_min_)\nprint(mms.data_max_)\njarak_scaled = mms.transform(jarak)\nprint(jarak_scaled.min())\nprint(jarak_scaled.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binwidth = 50\n\nax = plt.subplot(111)\nax.hist(jarak_scaled, bins = binwidth,\n             color = 'blue', edgecolor = 'black')\nax.set_title('Bin = %d' % binwidth, size = 30)\nax.set_xlabel('Jarak', size = 25)\nax.set_ylabel('Data', size= 25)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### ERROR ###\n\nk_means_riemann = Kmeans(n_clusters=3, n_jobs=-2)\nk_means_riemann.fit(data.values)\nclusters_riemann = k_means_riemann.fit_predict(data.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### SKIP ###\n\nplt.scatter(data.values[:, 1], data.values[:, 0], c=clusters_riemann, s=50, cmap='viridis')\n\ncenters_riemann = k_means_riemann.cluster_centers_\nplt.scatter(centers_riemann[:, 1], centers_riemann[:, 0], c='red', s=200, alpha=0.5);\nplt.gca().set_box_aspect(0.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### DBSCAN ###\n\ndb = DBSCAN(eps=0.3, min_samples=100).fit(data.values)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)\nprint(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\nprint(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\nprint(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\nprint(\"Adjusted Rand Index: %0.3f\"\n      % metrics.adjusted_rand_score(labels_true, labels))\nprint(\"Adjusted Mutual Information: %0.3f\"\n      % metrics.adjusted_mutual_info_score(labels_true, labels))\nprint(\"Silhouette Coefficient: %0.3f\"\n      % metrics.silhouette_score(data.values, labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}